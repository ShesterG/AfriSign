{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXPKfl80jBgh"
      },
      "source": [
        "# Clone Repo\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydUVUxTZBaQ9",
        "outputId": "520b3db7-1da5-4518-d41c-6b81d1b7f01f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AfriSign'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 44 (delta 7), reused 8 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ShesterG/AfriSign.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zs23FStRWHV",
        "outputId": "87de7047-b2be-48a2-829b-3e02d9feec34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUNk7RPZ5Pad"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8nZUVMpeITY",
        "outputId": "c491739e-69d5-417d-faa5-d3e66027869d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AfriSign/Datasets\n"
          ]
        }
      ],
      "source": [
        "%cd AfriSign/Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Requirements"
      ],
      "metadata": {
        "id": "h2KzZowjGWA8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVO12KRmjx51",
        "outputId": "29a58ade-44c7-462c-f303-40158ad07229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy==1.21.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.21.5)\n",
            "Requirement already satisfied: opencv-python==4.5.5.64 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.5.5.64)\n",
            "Requirement already satisfied: mediapipe==0.8.11 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.8.11)\n",
            "Requirement already satisfied: tensorflow==2.9.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.9.2)\n",
            "Requirement already satisfied: tensorflow-gpu==2.9.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.9.2)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.7/dist-packages (from mediapipe==0.8.11->-r requirements.txt (line 3)) (3.17.3)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe==0.8.11->-r requirements.txt (line 3)) (4.6.0.66)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe==0.8.11->-r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe==0.8.11->-r requirements.txt (line 3)) (22.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe==0.8.11->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (57.4.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (2.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (1.50.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (0.27.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (2.9.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (21.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (0.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (14.0.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2->-r requirements.txt (line 4)) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.2->-r requirements.txt (line 4)) (0.38.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.9.2->-r requirements.txt (line 4)) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe==0.8.11->-r requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe==0.8.11->-r requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe==0.8.11->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe==0.8.11->-r requirements.txt (line 3)) (0.11.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download videos"
      ],
      "metadata": {
        "id": "ZWTISNvUGZYk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "norE06_4LjYn"
      },
      "outputs": [],
      "source": [
        "#edit line13 of downloader, lan --> ase\n",
        "!python video_downloader.py --save_path /content/drive/MyDrive/Sign_Language_Videos/ase"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save infos about the video"
      ],
      "metadata": {
        "id": "wTo2AHY8GdFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python videos_info.py --save_path /content/drive/MyDrive/Sign_Language_Videos/ --sign_lang ase"
      ],
      "metadata": {
        "id": "6m5Lpl8vrsv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert videos to tensors"
      ],
      "metadata": {
        "id": "GSLVuWR6INRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python videos_to_tensors.py --save_path /content/drive/MyDrive/Sign_Language_Videos/ase"
      ],
      "metadata": {
        "id": "sB2lMZ-3IanI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Verse Text"
      ],
      "metadata": {
        "id": "DXCVHVznzz9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import sys\n",
        "import pickle\n",
        "import gzip\n",
        "!pip install requests\n",
        "import requests\n",
        "from google.colab import files\n",
        "from pathlib import \n",
        "from random import shuffle"
      ],
      "metadata": {
        "id": "ymrggZisz3Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hm6Hyj7wz5kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset_file(filename):\n",
        "    with gzip.open(filename, \"rb\") as f:\n",
        "        loaded_object = pickle.load(f)\n",
        "        return loaded_object"
      ],
      "metadata": {
        "id": "Wu-Y0xRzz6jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getBibleText(verse_name):\n",
        "  baseUrl = f'https://bible-api.com/{verse_name}'\n",
        "  res = requests.get(baseUrl)\n",
        "  json = res.json()\n",
        "  return json['text']"
      ],
      "metadata": {
        "id": "nTUcUlin2Q9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lan = \"ase\"\n",
        "data_list1 = load_dataset_file(f\"/content/drive/MyDrive/Sign_Language_Videos/dataset/{lan}1.dataset\")\n",
        "data_list2 = load_dataset_file(f\"/content/drive/MyDrive/Sign_Language_Videos/dataset/{lan}2.dataset\")\n",
        "data_list3 = load_dataset_file(f\"/content/drive/MyDrive/Sign_Language_Videos/dataset/{lan}3.dataset\")\n",
        "data_list4 = load_dataset_file(f\"/content/drive/MyDrive/Sign_Language_Videos/dataset/{lan}4.dataset\")\n",
        "data_list5 = load_dataset_file(f\"/content/drive/MyDrive/Sign_Language_Videos/dataset/{lan}5.dataset\")\n",
        "data_list6 = load_dataset_file(f\"/content/drive/MyDrive/Sign_Language_Videos/dataset/{lan}6.dataset\")\n",
        "data_list7 = load_dataset_file(f\"/content/drive/MyDrive/Sign_Language_Videos/dataset/{lan}7.dataset\")\n",
        "data_list8 = load_dataset_file(f\"/content/drive/MyDrive/Sign_Language_Videos/dataset/{lan}8.dataset\")\n",
        "data_list = data_list1 + data_list2 + data_list3 + data_list4 + data_list5 + data_list6 + data_list7 + data_list8"
      ],
      "metadata": {
        "id": "_J0wCb0bz6hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = load_dataset_file(f\"/content/drive/MyDrive/Sign_Language_Videos/dataset/T{lan}240.dataset\")"
      ],
      "metadata": {
        "id": "lPEY-g9Lz6d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_list)"
      ],
      "metadata": {
        "id": "2x9-rID96WxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verses = []\n",
        "unique_data_list = []\n",
        "for i in range(len(data_list)):\n",
        "  if data_list[i][\"name\"] in verses:\n",
        "    continue\n",
        "  else:\n",
        "    unique_data_list.append(data_list[i])\n",
        "    verses.append(data_list[i][\"name\"])"
      ],
      "metadata": {
        "id": "V1vSihOZz6YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "data_list = unique_data_list"
      ],
      "metadata": {
        "id": "yDygJVke9Ivx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_list)"
      ],
      "metadata": {
        "id": "3qmJ4gaZz6Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(data_list)):\n",
        "  #data_list[i][\"sign\"] = data_list[i][\"sign\"].to(dtype=torch.float32)\n",
        "    try:\n",
        "      data_list[i][\"text\"] = getBibleText(data_list[i][\"name\"])\n",
        "    except KeyError:\n",
        "      print(i)"
      ],
      "metadata": {
        "id": "VHoi1CT52Wje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_data_list = []\n",
        "for i in range(len(data_list)):\n",
        "  if data_list[i][\"text\"]==\"Text\":\n",
        "    continue\n",
        "  else:\n",
        "    unique_data_list.append(data_list[i])"
      ],
      "metadata": {
        "id": "b5alCCP_-eq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "data_list = unique_data_list"
      ],
      "metadata": {
        "id": "RL8WdJAeAwVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation_list = ['!',\n",
        " '\"',\n",
        " '#',\n",
        " '$',\n",
        " '%',\n",
        " '&',\n",
        " \"'\",\n",
        " '(',\n",
        " ')',\n",
        " '*',\n",
        " '+',\n",
        " ',',\n",
        " '-',\n",
        " '/',\n",
        " ':',\n",
        " ';',\n",
        " '<',\n",
        " '=',\n",
        " '>',\n",
        " '@',\n",
        " '[',\n",
        " '\\\\',\n",
        " ']',\n",
        " '^',\n",
        " '_',\n",
        " '`',\n",
        " '{',\n",
        " '|',\n",
        " '}',\n",
        " '~',\n",
        " '“',\n",
        " '”',\n",
        " '‘',\n",
        " '‘',\n",
        " '.',\n",
        " '?',\n",
        " '—']"
      ],
      "metadata": {
        "id": "QIjTjxJ12WfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(data_list)):\n",
        "  data_list[i][\"text\"] = data_list[i][\"text\"].lower().translate({ord(x): ' ' for x in punctuation_list}).replace('\\n', ' ').replace('’', '').replace('       ', ' ').replace('      ', ' ').replace('     ', ' ').replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').strip() + \" .\""
      ],
      "metadata": {
        "id": "9dl0nHJt2Wa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create vocab file"
      ],
      "metadata": {
        "id": "ndCCm3eMHNM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voc = set(\"<unk>\",\"<pad>\",\"<s>\",\"</s>\")\n",
        "for i in range(len(data_list)):\n",
        "  verse_words = data_list[i]['text'].split()\n",
        "  for vw in verse_words:\n",
        "    voc.add(vw) "
      ],
      "metadata": {
        "id": "HYXzoTml2WRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##to save in file\n",
        "with open(f'/content/drive/MyDrive/Sign_Language_Videos/dataset/{language}240/txt.vocab', 'w') as f:\n",
        "    for line in voc:\n",
        "        f.write(f\"{line}\\n\")"
      ],
      "metadata": {
        "id": "FNbYYFuGFYVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voclist = []\n",
        "for i in range(len(data_list)):\n",
        "  verse_words = data_list[i]['text'].split()\n",
        "  for vw in verse_words:\n",
        "    voclist.append(vw)"
      ],
      "metadata": {
        "id": "tGrJniGZ4cLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"length of vocabulary is {len(voc)}\")\n",
        "print(f\"total number of words in dataset is {len(voclist)}\")"
      ],
      "metadata": {
        "id": "WaoavQeaz6Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split into train, valid and test sets"
      ],
      "metadata": {
        "id": "AlRibMrOHXHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qTUM7qFGHW3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_list[0]"
      ],
      "metadata": {
        "id": "_oWMSjQy5EE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_list)"
      ],
      "metadata": {
        "id": "xMzLfUeyBNQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle(data_list)"
      ],
      "metadata": {
        "id": "TtUQL7cWBNNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = data_list[:2800] \n",
        "validation = data_list[2800:3100] \n",
        "testing = data_list[3100:] "
      ],
      "metadata": {
        "id": "jmY7GvdmBNKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(training))\n",
        "print(len(validation))\n",
        "print(len(testing))"
      ],
      "metadata": {
        "id": "MdMuVHjDEr1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_list(object, filename, protocol = 0):\n",
        "        \"\"\"Saves a compressed object to disk\n",
        "        \"\"\"\n",
        "        file = gzip.GzipFile(filename, 'wb')\n",
        "        file.write(pickle.dumps(object, protocol))\n",
        "        file.close()"
      ],
      "metadata": {
        "id": "0nlK9noPBNGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language = lan.upper()"
      ],
      "metadata": {
        "id": "K9SJk-o65Duy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_list(training,f\"/content/drive/MyDrive/Sign_Language_Videos/dataset/{language}240/{language}240.train\")\n",
        "save_list(validation,f\"/content/drive/MyDrive/Sign_Language_Videos/dataset/{language}240/{language}240.dev\")\n",
        "save_list(testing,f\"/content/drive/MyDrive/Sign_Language_Videos/dataset/{language}240/{language}240.test\")"
      ],
      "metadata": {
        "id": "WnOXDtfHFHk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i53VuXuQFN3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wotIq5nXFHh4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "learn-env",
      "language": "python",
      "name": "learn-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}